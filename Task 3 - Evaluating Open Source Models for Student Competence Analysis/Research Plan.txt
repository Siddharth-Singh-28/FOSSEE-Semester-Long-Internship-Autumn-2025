Research Plan
My approach to this evaluation would involve a structured investigation into open-source AI models suitable for educational analysis. Initially, I would focus on identifying models that have demonstrated proficiency in code analysis, natural language understanding, and question generation. My primary search would target models from popular open-source platforms like Hugging Face, specifically looking for fine-tuned LLMs or domain-specific models trained on code-related datasets.
To validate a model's applicability, I would set up a controlled testing environment. I would prepare a diverse set of Python code snippets written by students, including common mistakes, conceptual misunderstandings, and examples of correct but non-optimal solutions. I would then use the chosen model to generate prompts or insights based on this code. The model's output would be evaluated against a rubric focused on criteria like: relevance to the code, effectiveness in identifying misconceptions, and the ability to encourage deeper thought without simply providing the answer. This process would allow for a qualitative assessment of the model's performance in a real-world scenario.